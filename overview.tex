Dans cette section, nous décrivons l'architecture de notre outil sur
un corpus d'exemple. Nous justifions nos choix de conception par la
même occasion.

\yrg{Il faut dire à un moyen que l'on compare les définitions deux à deux
et non pas tous les sous-termes deux à deux.}

\paragraph{Que produit {\Asak}?}
La figure~\ref{fig:example:sources} contient les cinq
exemples de définitions {\OCaml} qui forment un corpus jouet
qui va nous servir à illustrer le fonctionnement d'{\Asak}.
Le lecteur aura reconnu d'un coup d'{\oe}il la fonction classique qui
renvoie la liste mirroir d'une liste prise en argument et l'enseignant
aura reconnnu des réponses typiques d'étudiants apprenti-programmeurs
fonctionnels.

\begin{figure}

\begin{ocaml}
(* Code 1 *)
let rec rev l = match l with
    [] -> []
  |t::q -> rev q@[t]

(* Code 2 *)
let rec rev l =
  match l with
  | [] -> []
  | a::t -> (rev t)@[a]

(* Code 3 *)
let rec rev l = match l with
    [] | [_] -> l
  | t::q -> rev q@[t];;

(* Code 4 *)
let rev l=
  let rec rev_aux acc l=
    match l with
    |[]->acc
    |t::q->rev_aux (t::acc) q
  in rev_aux [] l

(* Code 5 *)
let rev l =
  match l with
    [] -> []
  |a::q -> let rec rev2 x y = match y with
        [] -> x
      |b::z -> rev2 (b::x) z in rev2 [] l

(* Code 6 *)
let rev l =
  List.fold_left (fun acc x -> x :: acc) [] l
\end{ocaml}

\label{fig:example:sources}
\caption{Un corpus jouet pour illustrer notre algorithme.}
\end{figure}

Sur ce corpus, notre outil produit le dendrogramme suivant~:

\begin{center}
\begin{tikzpicture}[sloped, scale=0.5]
\node (a)  at (-6,0)   {1};
\node (b)  at (-5,0)   {2};
\node (ab) at (-5.5,1) {};
\node (c) at (-3,0) {3};
\node (abc) at (-4, 2) {};
\node (d) at (-2,0) {4};
\node (e) at (-1,0) {5};
\node (de) at (-1.5,2) {};
\node (abcde) at (-3.5, 3) {};
\node (f) at (0,0) {6};
\node (all) at (-1, 4) {};
\node (root) at (-1,5) {};

\draw  (a) |- (ab.center);
\draw  (b) |- (ab.center);
\draw  (ab) |- (abc.center);
\draw  (c)  |- (abc.center);
\draw  (abc) |- (abcde.center);
\draw  (de)  |- (abcde.center);
\draw  (d)  |- (de.center);
\draw  (e)  |- (de.center);

\draw  (abcde) |- (all.center);
\draw  (f)     |- (all.center);

\draw (all)      |- (root.center);

\draw[->,-triangle 60] (-7,0) -- node[above]{dissimilarité} (-7,6);
\end{tikzpicture}
\end{center}

Un dendrogramme est un arbre binaire dont les n{\oe}uds représentent
des classes d'individus. Les feuilles de ce dendrogramme sont les
différentes versions de \texttt{rev}. Un dendrogramme fournit un
partitionnement hiérarchique d'un ensemble d'invididus: en le
parcourant d'une feuille vers sa racine, on découvre des classes
d'invididus de plus en plus dissimilaires à cette feuille ; en le
parcourant de sa racine vers ses feuilles, on découvre des séparations
successives en deux classes d'un ensemble d'individus maximisant
la dissimilarité entre les membres des deux classes. \yrg{Formulation
un peu lourde et peut-être incorrecte. Alexandre, tu peux m'aider?} \am{Peut-être peut-on expliquer en utilisant la construction même de l'arbre: Choisissant pour distance entre deux arbres le maximum des dissimilarités entre leurs feuilles, on construit le dendrogramme en commençant avec un collection de feuilles puis en agglomérant les arbres les plus proches. Ainsi, plus deux feuilles ont un parent proche, plus elles sont similaires comparé aux autres feuilles.}

Dans le cas de ce corpus, le regroupement des définitions~$1$ et~$2$
est très naturel puisque ces deux définitions sont équivalentes à
quelques détails purement textuels près : la présence du \iocaml{|},
d'un retour à la ligne et d'un renommage. La définition~$3$ est proche
de cette première classe: elle en diffère seulement à cause d'un cas
d'analyse supplémentaire. Le regroupement des définitions~$4$ et~$5$
est assez naturel puisqu'elles suivent la même (et bonne!) stratégie
qui consiste à accumuler le résultat dans l'argument d'une fonction
auxiliaire interne. Notons que ces deux définitions ne sont pas
syntaxiquement équivalence même si elles utilisent les mêmes ``ingrédients'' :
la définition~$5$ effectue une analyse par cas supplémentaire pour
traiter le cas de la liste vide de façon spécifique. Les deux classes~$(1-2)-3$
et~$4-5$ partagent le fait d'être des définitions récursives procédant par
analyse de cas : ces individus sont clairement séparés de la définition~$6$
qui s'appuie sur une spécialisation de la fonction~\iocaml{List.fold_left}.

\paragraph{Comment procède {\Asak}?}
Ce partitionnement semble somme toute assez naturel mais comment notre
outil l'a-t-il obtenu? Comme nous l'avons déjà écrit dans
l'introduction, le traitement de notre outil se décompose
essentiellement en trois étapes: (i) les programmes sources sont
normalisés pour ignorer les détails syntaxiques que nous jugeons
inessentiels ; (ii) on calcule une empreinte pour caractériser la
structure et les ingrédients principaux des programmes normalisés ;
(iii) on applique un algorithme de partitionnement hiérarchique qui
s'appuie sur les empreintes.
\yrg{Rajouter une figure?}

\paragraph{Comment les définitions sont-elles normalisées?}
L'analyse syntaxique est la solution canonique pour éliminer les
artefacts textuels et ne garder que la structure d'un code source.
Notre outil travaille donc sur des arbres de syntaxe abstraits.  On
pourrait opposer à ce choix de conception le fait que considérer le
texte des programmes permettrait de séparer des programmes dont les
arbres de syntaxe sont égaux. Cependant, un tel point de vue sépare
trop de programmes.

Une fois que l'on a décidé de travailler sur un langage d'arbres
distincts de la syntaxe concrète, il faut choisir ce nouveau langage.
On aurait pu choisir de traduire les termes sources vers un langage
conçu pour l'occasion mais ce serait beaucoup de travail. Il existe
heureusement le langage intermédiaire {\LambdaCode} dans le
compilateur et nos expérimentations nous portent à croire qu'il se
place au bon niveau d'abstraction pour capturer la structure
calculatoire du programme source.

Ce langage sera présenté précisément dans la section~\ref{sec:lambda}
mais nous pouvons d'ores et déjà donner la traduction du corpus jouet
dans la figure~\ref{fig:lambda-corpus}. Pour réaliser cette
traduction, nous réutilisons la partie avant du compilateur~{\OCaml}
et nous effectuons un post-traitement qui normalise encore un peu plus
les termes. Les détails de cette traduction seront décrits dans la
section~\ref{sec:lambda-normalization}. Sur nos exemples, on peut déjà
remarquer que les définitions~$1$ et~$2$ sont identiques une fois
normalisées. On note aussi que la définition~$3$ normalisée partage
des sous-termes avec les définitions~$1$ et $2$ normalisées. Des
remarques similaires s'appliquent aux autres définitions.

\begin{figure}
\begin{lisp}
Définition 1:
(function l/88
  (if l/88
    (apply (field 36 (global Stdlib!)) (apply rev/87 (field 1 l/88))
      (makeblock 0 (field 0 l/88) 0a))
    0a))

Définition 2:
(function l/88
  (if l/88
    (apply (field 36 (global Stdlib!)) (apply rev/87 (field 1 l/88))
      (makeblock 0 (field 0 l/88) 0a))
    0a))

Définition 3:
(function l/88
  (catch
    (if l/88
      (if (field 1 l/88)
        (apply (field 36 (global Stdlib!)) (apply rev/87 (field 1 l/88))
          (makeblock 0 (field 0 l/88) 0a))
        (exit 12))
      (exit 12))
   with (12) l/88))

Définition 4:
(function l/88
  (letrec
    (rev_aux/89
       (function acc/90 l/91
         (if l/91
           (apply rev_aux/89 (makeblock 0 (field 0 l/91) acc/90)
             (field 1 l/91))
           acc/90)))
    (apply rev_aux/89 0a l/88)))

Définition 5:
(function l/88
  (if l/88
    (letrec
      (rev2/91
         (function x/92 y/93
           (if y/93
             (apply rev2/91 (makeblock 0 (field 0 y/93) x/92) (field 1 y/93))
             x/92)))
      (apply rev2/91 0a l/88))
    0a))

Définition 6:
(function l/88
  (apply (field 20 (global Stdlib__list!))
    (function acc/146 x/147 (makeblock 0 x/147 acc/146)) 0a l/88))
\end{lisp}
\caption{Traduction du corpus dans le code {\LambdaCode} du compilateur~\OCaml.}
\label{fig:lambda-corpus}
\end{figure}

\paragraph{Pourquoi calcule-t-on des empreintes?}

Comparer deux arbres en itérant sur leurs structures respectives a un
coût proportionnel à leur taille. Par ailleurs, la notion de
comparaison qui nous intéresse doit idéalement savoir comparer
l'ensemble des sous-arbres des deux arbres pour déterminer à quel
point ils sont construits avec des ingrédients similaires, i.e.  à
quel point ils ont du code en commun. L'ordre d'apparition des
sous-arbres n'est donc pas forcément important : bien entendu, deux
arbres utilisant les mêmes sous-arbres dans le même ordre seront
très similaires mais utiliser les mêmes sous-arbres dans un ordre
différent est aussi une forme de similarité non négligeable même
si elle est un peu moins forte.

Après ces remarques, l'implémentation d'une fonction d'évaluation de
la similarité entre deux termes $\LambdaCode$ semble difficile. Nous
introduisons les empreintes d'arbres pour simplifier cette
implémentation et aussi pour la rendre efficace. Les empreintes sont
des ensembles de clés de hachages des sous-termes (suffisamment gros)
du terme $\LambdaCode$. L'idée importante de cette notion d'empreinte
est de prendre en compte l'ordre relatif des sous-termes dans le
calcul de la clé de hachage mais de voir l'empreinte comme un ensemble
de clés pour maintenir une certaine proximité entre les termes qui
utilisent les mêmes sous-termes, mais dans un ordre différent. Ainsi,
les deux programmes suivants:
\begin{ocaml}
let f () = e1; e2
let g () = e2; e1
\end{ocaml}
\noindent ont pour empreintes:
\[
\begin{array}{rcl}
E(\iocaml{f}) &=& \{ H(\iocaml{e1; e2}), H(\iocaml{e1}), H(\iocaml{e2}) \} \\
E(\iocaml{g}) &=& \{ H(\iocaml{e2; e1}), H(\iocaml{e1}), H(\iocaml{e2}) \}
\end{array}
\]
\noindent où $E(t)$ est l'empreinte de $t$ et $H(t)$ est la clé de hachage de $t$.

Ces deux empreintes sont distinctes mais partagent deux clés de
hachage. Ce partage témoigne du fait qu'elles ``utilisent les mêmes
ingrédients''. Les empreintes calculées pour les définitions de notre
corpus jouet se trouvent dans la figure~\ref{fig:hash} Nous décrivons
la définition précise de cette prise d'empreintes dans la
section~\ref{sec:hash}.

\begin{figure}
TODO
\caption{Les empreintes des définitions de notre corpus jouet.}
\label{fig:hash}
\end{figure}

\paragraph{Comment le partitionnement hiérarchique est-il effectué?}
