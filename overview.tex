Dans cette section, nous décrivons l'architecture de notre outil sur
un corpus d'exemple. Nous expliquons nos choix de conception par la
même occasion.

\input{revs}

\paragraph{Que produit {\Asak}?}
{\Asak} cherche à comparer entre elles des définitions globales.  La
figure~\ref{fig:example:sources} contient cinq exemples de telles
définitions {\OCaml}. Elles forment un corpus jouet qui va nous servir
à illustrer le fonctionnement d'{\Asak}.  Le lecteur aura reconnu d'un
coup d'{\oe}il la fonction classique qui renvoie la liste mirroir
d'une liste prise en argument et l'enseignant aura reconnnu des
réponses typiques d'étudiants apprenti-programmeurs fonctionnels.

Sur ce corpus, notre outil produit l'ensemble de dendrogrammes suivants~:

\begin{center}
\begin{tikzpicture}[sloped, scale=0.5]
\node (a)  at (-6,0)   {1};
\node (b)  at (-5,0)   {2};
\node (ab) at (-5.5,1) {};
\node (c) at (-3,0) {3};
\node (abc) at (-4, 2) {};
\node (d) at (-2,0) {4};
\node (e) at (-1,0) {5};
\node (de) at (-1.5,2) {};
% \node (abcde) at (-3.5, 3) {};
\node (f) at (0,0) {6};
%\node (all) at (-1, 4) {};
%\node (root) at (-1,5) {};

\draw  (a) |- (ab.center);
\draw  (b) |- (ab.center);
\draw  (ab) |- (abc.center);
\draw  (c)  |- (abc.center);
%\draw  (abc) |- (abcde.center);
%\draw  (de)  |- (abcde.center);
\draw  (d)  |- (de.center);
\draw  (e)  |- (de.center);

%\draw  (abcde) |- (all.center);
%\draw  (f)     |- (all.center);

%\draw (all)      |- (root.center);

\draw[->,-triangle 60] (-7,0) -- node[above]{dissimilarité} (-7,6);
\end{tikzpicture}
\end{center}

Un dendrogramme est un arbre binaire dont les n{\oe}uds représentent
des classes d'individus. Les feuilles de ce dendrogramme sont les
différentes versions de \texttt{rev}. Un dendrogramme fournit un
partitionnement hiérarchique d'un ensemble d'invididus: en le
parcourant d'une feuille vers sa racine, on découvre des classes
d'invididus de plus en plus dissimilaires à cette feuille ; en le
parcourant de sa racine vers ses feuilles, on découvre des séparations
successives en deux classes d'un ensemble d'individus maximisant
la dissimilarité entre les membres des deux classes. \yrg{Formulation
un peu lourde et peut-être incorrecte. Alexandre, tu peux m'aider?} \am{Peut-être peut-on expliquer en utilisant la construction même de l'arbre: Choisissant pour distance entre deux arbres le maximum des dissimilarités entre leurs feuilles, on construit le dendrogramme en commençant avec un collection de feuilles puis en agglomérant les arbres les plus proches. Ainsi, plus deux feuilles ont un parent proche, plus elles sont similaires comparé aux autres feuilles.}

Dans le cas de ce corpus, le regroupement des définitions~$1$ et~$2$
est très naturel puisque ces deux définitions sont équivalentes à
quelques détails purement textuels près : la présence du \iocaml{|},
d'un retour à la ligne et d'un renommage. La définition~$3$ est proche
de cette première classe: elle en diffère seulement à cause d'un cas
d'analyse supplémentaire. Le regroupement des définitions~$4$ et~$5$
est assez naturel puisqu'elles suivent la même (et bonne!) stratégie
qui consiste à accumuler le résultat dans l'argument d'une fonction
auxiliaire interne. Notons que ces deux définitions sont dissimilaires
même si elles utilisent les mêmes ``ingrédients'' : la définition~$5$
effectue une analyse par cas supplémentaire pour traiter le cas de la
liste vide de façon spécifique.
%% Les deux classes~$(1-2)-3$
%% et~$4-5$ partagent le fait d'être des définitions récursives procédant par
%% analyse de cas : ces individus sont clairement séparés de la définition~$6$
%% qui s'appuie sur une spécialisation de la fonction~\iocaml{List.fold_left}.

%% L'intérêt d'une classification hiérarchique est surtout visible sur de
%% grands corpus : les quelques classes les plus proches de la racine du
%% dendrogramme sont les principales classes de définitions similaires
%% -- celles qui partagent au moins un sous-terme -- et c'est
%% en observant chaque classe en profondeur que l'on raffine petit à
%% petit les différences entre ses membres.

\paragraph{Comment procède {\Asak}?}
Ce partitionnement semble assez naturel mais comment
notre outil l'a-t-il obtenu? Comme nous l'avons déjà écrit dans
l'introduction, le traitement de notre outil se décompose
essentiellement en trois étapes: (i) les programmes sources sont
normalisés pour ignorer les détails syntaxiques que nous jugeons
inessentiels ; (ii) on calcule une empreinte pour caractériser la
structure et les ingrédients principaux des programmes normalisés ;
(iii) on applique un algorithme de partitionnement hiérarchique qui
s'appuie sur les empreintes.

\paragraph{Comment les définitions sont-elles normalisées?}
L'analyse syntaxique est la solution canonique pour éliminer les
artefacts textuels et ne garder que la structure d'un code source.
Notre outil travaille donc sur des arbres de syntaxe abstraits.  On
pourrait opposer à ce choix de conception le fait que considérer le
texte des programmes permettrait de séparer des programmes dont les
arbres de syntaxe sont égaux. Cependant, un tel point de vue sépare
trop de programmes.

Une fois que l'on a décidé de travailler sur un langage d'arbres
distincts de la syntaxe concrète, il faut choisir ce nouveau langage.
On aurait pu choisir de traduire les termes sources vers un langage
conçu pour l'occasion mais ce serait beaucoup de travail. Il existe
heureusement le langage intermédiaire {\LambdaCode} dans le
compilateur et nos expérimentations nous portent à croire qu'il se
place au bon niveau d'abstraction pour capturer la structure
calculatoire du programme source.

Ce langage sera présenté précisément dans la section~\ref{sec:lambda}
mais nous pouvons d'ores et déjà donner la traduction du corpus jouet
dans la figure~\ref{fig:lambda-corpus}. Pour réaliser cette
traduction, nous réutilisons la partie avant du compilateur~{\OCaml}
et nous effectuons un post-traitement qui normalise encore un peu plus
les termes. Les détails de cette traduction seront décrits dans la
section~\ref{sec:lambda}. Sur nos exemples, on peut déjà
remarquer que les définitions~$1$ et~$2$ sont identiques une fois
normalisées. On note aussi que la définition~$3$ normalisée partage
des sous-termes avec les définitions~$1$ et $2$ normalisées. Des
remarques similaires s'appliquent aux autres définitions.

\input{lambda-corpus}

\paragraph{Pourquoi calcule-t-on des empreintes?}

Comparer deux arbres en itérant sur leurs structures respectives a un
coût proportionnel à leur taille. Par ailleurs, la notion de
comparaison qui nous intéresse doit idéalement savoir comparer
l'ensemble des sous-arbres des deux arbres pour déterminer à quel
point ils sont construits avec des ingrédients similaires, i.e.  quelle
quantité de code ils ont en commun. L'ordre d'apparition des
sous-arbres n'est donc pas forcément important : bien entendu, deux
arbres utilisant les mêmes sous-arbres dans le même ordre seront
très similaires mais utiliser les mêmes sous-arbres dans un ordre
différent est aussi une forme de similarité non négligeable même
si elle est un peu moins forte.

Après ces remarques, l'implémentation d'une fonction d'évaluation de
la similarité entre deux termes $\LambdaCode$ semble difficile. Nous
introduisons les empreintes d'arbres pour simplifier cette
implémentation et aussi pour la rendre efficace. Les empreintes sont
des ensembles de clés de hachages des sous-termes (suffisamment gros)
du terme $\LambdaCode$. L'idée importante de cette notion d'empreinte
est de prendre en compte l'ordre relatif des sous-termes dans le
calcul de la clé de hachage tout en regardant aussi l'empreinte comme un ensemble
de clés pour maintenir une certaine proximité entre les termes qui
utilisent les mêmes sous-termes, mais dans un ordre différent. Ainsi,
les deux programmes suivants:
\begin{ocaml}
let f () = e1; e2
let g () = e2; e1
\end{ocaml}
\noindent ont pour empreintes:
\[
\begin{array}{rcl}
E(\iocaml{f}) &=& \{ H(\iocaml{e1; e2}), H(\iocaml{e1}), H(\iocaml{e2}) \} \\
E(\iocaml{g}) &=& \{ H(\iocaml{e2; e1}), H(\iocaml{e1}), H(\iocaml{e2}) \}
\end{array}
\]
\noindent où $E(t)$ est l'empreinte de $t$ et $H(t)$ est la clé de hachage de $t$.

Ces deux empreintes sont distinctes mais partagent deux clés de
hachage. Ce partage témoigne du fait qu'elles ``utilisent les mêmes
ingrédients''. Les empreintes calculées pour les définitions de notre
corpus jouet se trouvent dans la figure~\ref{fig:hash}. On distingue
la liste numérotée des clés de hachage dans la partie haute de la figure.
En bas de la figure, on trouve les empreintes des définitions, ce sont
des multi-ensembles de paires d'entiers. Dans cette figure, l'entier
du haut est le numéro de clé de hachage et l'entier du  bas est le
nombre de n{\oe}uds de l'arbre de syntaxe du sous-terme haché.
%
Nous donnons la définition précise de cette prise d'empreintes dans la
section~\ref{sec:hash}.

\begin{figure}
{\tiny\input{hash-corpus}}
\caption{Les empreintes des définitions de notre corpus jouet.}
\label{fig:hash}
\end{figure}

\paragraph{Comment le partitionnement hiérarchique est-il effectué?}

Il existe deux grandes familles de partitionnement hiérarchique : les
partitionnements ascendants et les partitionnements descendants. Les
partitionnements ascendants sont adaptés aux corpus formés de petits
groupes tandis que les partitionnements descendants à ceux formés de
grands groupes. Nous avons fait l'hypothèse que les groupes de
définitions similaires sont petits par rapport au corpus et nous avons
donc choisi un algorithme de partitionnement hiérarchique ascendant.

L'algorithme procède donc en partant d'un partitionnement où chaque
individu est dans une classe distincte de celles des autres et choisi
à chaque itération de fusionner les deux classes les moins
dissimilaires. Nous définirons précisément la mesure de dissimilarité
que nous utilisons dans la section~\ref{sec:clustering} mais pour
se donner une idée du fonctionnement de l'algorithme, le lecteur
pourra en observer la trace d'exécution sur notre corpus jouet
dans la figure~\ref{fig:clustering-jouet}.

\begin{figure}

Donner la (demi-)matrice de dissimilarité.

Donner les étapes du partitionnements (avec les valeurs de dissimilarité entre classes).

\caption{Trace du partitionnement des définitions du corpus jouet s'appuyant sur la dissimilarité
des définitions entre elles.}
\label{fig:clustering-jouet}
\end{figure}

