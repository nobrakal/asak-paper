%!TEX root = root.tex

Partitionner un corpus vis-à-vis de l'égalité entre empreintes permet
déjà de regrouper des programmes syntaxiquement distincts mais qui
partagent exactement la même structure. Nous souhaitons aller plus loin en regroupant des
programmes qui se ressemblent même si leurs structures respectives
diffèrent légèrement. Considérons par exemple:

\begin{ocaml}
let id1 x = print_endline "debug"; x
let id2 x = x
\end{ocaml}
\noindent \iocaml{id1} et \iocaml{id2} n'ont pas le même glyphe mais
on peut difficilement ignorer leur ressemblance!

Comme nous l'avons expliqué précédemment, nous utilisons un algorithme
de partitionnement hiérarchique ascendant qui a besoin d'une notion
de dissimilarité pour fonctionner.

\begin{defn}
Soient $X$ et $Y$ deux empreintes. La \textit{dissimilarité} $d(X, Y)$ entre~$X$ et~$Y$
est une valeur de $\mathbb{N} \cup \{ \infty \}$ définie comme suit:
\begin{align*}
d (X,Y) &=
\begin{cases}
	\infty & \text{si $X \cap Y = \emptyset$} \\
	\sum\limits_{g \in X \Delta Y} w(g) & \text{sinon}
\end{cases}
\end{align*}
\noindent où $X \Delta Y$ est la différence symétrique entre deux multi-ensembles~$X$ et~$Y$.
\end{defn}

Cette définition n'est pas très standard car elle sépare de façon très
brutale les programmes qui ne partagent aucun sous-terme. Ce choix
garantit que deux programmes sans rapport ne pourront jamais
apparaître dans la même classe. Ainsi, le dendrogramme final sera
composé d'une union de classes infiniment distantes les unes des
autres. Nous pensons que cette propriété améliore la lisibilité des
résultats. Un autre avantage de cette définition est de permettre
d'accélérer significativement l'algorithme de partitionnement: quand
un individu est infiniment éloigné d'une classe~$C$, il n'est plus
nécessaire de le comparer avec les classes parentes de~$C$.

Notez que cette notion de dissimilarité n'est pas une distance. En
effet, elle ne vérifie pas l'inégalité triangulaire. Par contre, cette
dissimilarité est une fonction de séparation ($\forall X,Y,\ d(X,Y) =
0 \iff X = Y$) et symétrique ($\forall X,Y,\ d(X,Y) = d(Y,X)$). Cette
propriété est suffisante pour appliquer notre algorithme de
partitionnement.

L'algorithme procède par itération sur une liste de classes
d'empreintes. On suppose que l'on sait fusionner deux classes
d'empreintes et que l'on garde trace de ces fusions pour pouvoir
produire un dendrogramme par classe.

\begin{ocaml}
(* Types pour les classes d'empreintes et les partionnements. *)
type cluster and clustering = cluster list
(* L'opération de fusion. *)
val merge : cluster -> cluster -> clustering -> clustering
(* Une classe avec une unique empreinte. *)
val singleton : fingerprint -> cluster
\end{ocaml}

Il faut étendre la notion de dissimilarité aux paires de classes.

\begin{defn}
La dissimilarité~$d(\alpha, \beta)$ entre deux classes
d'empreintes~$\alpha$ et~$\beta$ est:
\begin{align*}
d(\alpha,\beta) &= \max\limits_{X \in \alpha, Y \in \beta} d(X,Y)
\end{align*}
\end{defn}

Cette définition de la dissimilarité inter-classes est classique et
donne lieu à un partitionnement à liaison complète (\emph{complete
  linkage clustering}).\yrg{Citation!}

Enfin, on suppose l'existence d'une fonction capable de déterminer
les deux classes les plus proches dans le partitionnement courant:

\begin{ocaml}
type dissimilarity = Regular of int | Infinity

(* Renvoie les deux clusters les plus proches selon d, ainsi que leur distance *)
val get_closest_with_d : clustering -> (dissimilarity * (cluster * cluster))
\end{ocaml}

L'algorithme de partitionnement hiérarchique est donné par le programme {\OCaml} suivant:

\begin{ocaml}
(* Renvoie une liste de classes deux à deux infiniment dissimilaires. *)
let rec run_clustering xs =
  match xs with
  | [] | [_] -> xs
  | _ -> match get_closest_with_d xs with
         | (Infinity, _) -> xs
         | (Regular p, (u, v)) -> run_clustering (merge u v xs)

let make_clusters : fingerprint list -> cluster list = fun fs ->
  run_clustering @@ List.map singleton fs
\end{ocaml}

Cette formulation de l'algorithme est malheureusement trop naïve pour
être implémentée directement. En effet, en pire cas, la complexité de
cet algorithme est cubique en fonction de la longueur de la
liste~\iocaml{fs}, c'est-à-dire du nombre de définitions du
corpus et dans nos cas d'usage, ce nombre de l'ordre de~$10^6$.

\yrg{Faire le point avec Alexandre sur les optimisations :
  surapproximation et parallélisme, c'est tout?}
